{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit recognizer using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST (“Modified National Institute of Standards and Technology”) is the de facto “Hello World” dataset of computer vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains 60,000 traning images and 10000 testing images. Here I split the data into training and testing datasets respectively. The x_train & x_test contains grayscale codes while y_test & y_train contains labels from 0–9 which represents the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have (60000,28,28) as our shape of the dataset which means that we have 60000 images in our dataset and size of each image is 28 * 28 pixel.\n",
    "To use Keras API we need a 4-dimensional array but we can see from above that we have a 3-dimension numpy array.\n",
    "So, here we convert the 3-dimension numpy array into 4-dimensional and after we set the type as float to have floating values after the division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now coming to the normalizing part, this is done by dividing it by 255 (which is the maximum RGB code minus the minimum RGB code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had import the Sequential Model from Keras and added Conv2D, MaxPooling, Flatten, Dropout, and Dense layers.\n",
    "Dropout layers helps to fight with the overfitting by disregarding some of the neurons while training while Flatten layers flatten 2D arrays to 1D array before building the fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling and fitting the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have created an non-optimized empty CNN. Then I set an optimizer with a given loss function which uses a metric and fit the model by using our train data. The ADAM optimizer is said to outperform the other optimizers, that’s why I used that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.3612 - accuracy: 0.8921\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0881 - accuracy: 0.9730\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0557 - accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0429 - accuracy: 0.9865\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0315 - accuracy: 0.9903\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0254 - accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0249 - accuracy: 0.99150s\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0177 - accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0177 - accuracy: 0.9940\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0155 - accuracy: 0.99470s - loss: 0.015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c8c036ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0625 - accuracy: 0.9846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.062498487532138824, 0.9846000075340271]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOGElEQVR4nO3de4hcdZrG8ecxa/AWQtw0MRjdzg6iyOqqFLJq4gXZ0fiPjohMEHVQzPwR0cEIK/GKIMiyM+MIq5BZw2SWWcPAKImSuJOVgTiCEyuaSaLi6koHDbm0BDHiNcm7f/TJTKtdp9o6py7p9/uBpqrPW1W/l5M8farOqXN+jggBmPqO6ncDAHqDsANJEHYgCcIOJEHYgST+ppeDzZ49O4aHh3s5JJDKyMiIPvzwQ09UqxR221dK+oWkaZL+IyIeLXv88PCwms1mlSEBlGg0Gi1rHb+Ntz1N0r9LWiTpTEmLbZ/Z6esB6K4qn9nPl/RuRLwXEV9KWi3p6nraAlC3KmE/WdL7437/oFj2NbaX2G7abo6OjlYYDkAVXd8bHxErIqIREY2hoaFuDweghSph3ynplHG/zyuWARhAVcL+qqTTbM+3PV3SDyWtractAHXr+NBbRBywfbuk/9bYobeVEfFGbZ0BqFWl4+wRsU7Supp6AdBFfF0WSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJCrN4op6bNq0qbR+wQUXlNYff/zxlrWlS5d21BOmnkphtz0iab+kg5IORESjjqYA1K+OLftlEfFhDa8DoIv4zA4kUTXsIen3tjfbXjLRA2wvsd203RwdHa04HIBOVQ37gog4T9IiSUttX/zNB0TEiohoRERjaGio4nAAOlUp7BGxs7jdK+lZSefX0RSA+nUcdtvH255x+L6k70vaXldjAOpVZW/8HEnP2j78Ov8VES/U0lUyd911V2m9WMcdPf/CCy8sfe65555bWsfU0XHYI+I9Sf9YYy8AuohDb0AShB1IgrADSRB2IAnCDiTBKa498Nhjj5XWN2/eXOn1Dx482LJ22223lT53+fLlpfW77767o54OO3ToUMvaUUdN3W3NLbfcUlq/7777etTJX03dtQ3gawg7kARhB5Ig7EAShB1IgrADSRB2IAlHRM8GazQa0Ww2ezZer2zcuLG0fsUVV5TWv/rqqzrbGShl/7/anbp7JGv3HYI1a9a0rC1atKjjcRuNhprN5oQrli07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTB+ew1OO6440rr06ZNK61P5ePsWbX7N58xY0aPOvkrtuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATH2WvQaDRK6wsXLiytb9iwoc52vqbddwAuuuii0vp1111X6fmDateuXaX1xYsXl9b3799fWn/yySdL6wsWLCitd0PbLbvtlbb32t4+btmJtjfYfqe4ndXdNgFUNZm38b+SdOU3lt0j6cWIOE3Si8XvAAZY27BHxEZJ+76x+GpJq4r7qyRdU29bAOrW6Q66ORFx+EPPbklzWj3Q9hLbTdvN0dHRDocDUFXlvfExdkXBllcVjIgVEdGIiMbQ0FDV4QB0qNOw77E9V5KK2731tQSgGzoN+1pJNxf3b5bU+rq4AAZC2+Pstp+WdKmk2bY/kPSgpEcl/db2rZJ2SLq+m00e6VavXl1aP++880rrO3bs6Hjs008/vbS+fv36jl/7SHbGGWeU1l955ZXServj7GedddZ37qnb2oY9Ilp9u+DymnsB0EV8XRZIgrADSRB2IAnCDiRB2IEkOMW1B2bOnFlaX7ZsWWn9jjvuqLMdTMLw8HC/W6gdW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILj7AOg3aWoqzh48GBp/csvvyytT58+vc520Eds2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCY6zT3Fbt24trc+dO7e0fv/991ca//LLW1+EeBAvtzyVsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zj4ATj311NL6vHnzSuvvv/9+x2N/9NFHpfV217Rv59ChQy1rRx1Vvq25+OKLS+vr1q0rrR977LGl9Wzabtltr7S91/b2ccsesr3T9pbi56rutgmgqsm8jf+VpCsnWP7ziDin+Cn/Ewug79qGPSI2StrXg14AdFGVHXS3295avM2f1epBtpfYbtpujo6OVhgOQBWdhv1JSd+TdI6kXZJ+2uqBEbEiIhoR0RgaGupwOABVdRT2iNgTEQcj4pCkX0o6v962ANSto7DbHn9e5A8kbW/1WACDoe1xdttPS7pU0mzbH0h6UNKlts+RFJJGJP24ey1OfSeddFJp/ZFHHimtP/jggy1rIyMjnbRUm7Jj6bZLn/vSSy+V1tudi3/ttde2rK1cubL0uVNR27BHxOIJFj/VhV4AdBFflwWSIOxAEoQdSIKwA0kQdiAJTnE9Atxwww2l9bJDTAcOHCh97gsvvFBa37RpU2m9nWaz2bLW7tBaO5988klp/bPPPqv0+lMNW3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMIR0bPBGo1GlB13xdRTdqy73Wmmd955Z6WxTzjhhJa1119/vfS58+fPrzR2vzQaDTWbzQnPHWbLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD47uuqLL75oWdu3r7tTCJZN2Xz00Ud3dexBxJYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgOPsUMDo62rL26aefVnrttWvXltZffvnl0vq2bdta1t5+++2OepqsG2+8sWVt3rx5XR17ELXdsts+xfYfbL9p+w3bdxbLT7S9wfY7xe2s7rcLoFOTeRt/QNKyiDhT0j9JWmr7TEn3SHoxIk6T9GLxO4AB1TbsEbErIl4r7u+X9JakkyVdLWlV8bBVkq7pUo8AavCddtDZHpZ0rqQ/SZoTEbuK0m5Jc1o8Z4ntpu1m2WdLAN016bDbPkHS7yT9JCI+Hl+LsatWTnjlyohYERGNiGgMDQ1VahZA5yYVdttHayzov4mIZ4rFe2zPLepzJe3tTosA6tD20JttS3pK0lsR8bNxpbWSbpb0aHG7pisdHgE+//zz0vq9995bWv/4449L6+2sX7++ZW337t2VXruqskuVj/3X6txNN91UWn/44Ycrvf5UM5nj7BdJulHSNttbimXLNRby39q+VdIOSdd3pUMAtWgb9oj4o6RWf4Ivr7cdAN3C12WBJAg7kARhB5Ig7EAShB1IglNcJ6nsksiLFy8ufe5zzz1XdztHjJkzZ7aszZpVfqLkJZdcUlp/4oknSuvHHHNMaT0btuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATH2SfpmWeeaVl7/vnne9jJt02bNq1lbcaMGZVeu9054+2OhZ999tkta/Pnz++oJ3SGLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMFx9kkqO2d96dKlpc+tel34Bx54oLS+cOHClrXLLrus0tiYOtiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASk5mf/RRJv5Y0R1JIWhERv7D9kKTbJI0WD10eEeu61egg27dvX79bANqazJdqDkhaFhGv2Z4habPtDUXt5xHxb91rD0BdJjM/+y5Ju4r7+22/JenkbjcGoF7f6TO77WFJ50r6U7Hodttbba+0PeFcPraX2G7abo6Ojk70EAA9MOmw2z5B0u8k/SQiPpb0pKTvSTpHY1v+n070vIhYERGNiGgMDQ1V7xhARyYVdttHayzov4mIZyQpIvZExMGIOCTpl5LO716bAKpqG3bblvSUpLci4mfjls8d97AfSNpef3sA6jKZvfEXSbpR0jbbW4plyyUttn2Oxg7HjUj6cRf6A1CTyeyN/6MkT1BKeUwdOFLxDTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjojeDWaPStoxbtFsSR/2rIHvZlB7G9S+JHrrVJ29/V1ETHj9t56G/VuD282IaPStgRKD2tug9iXRW6d61Rtv44EkCDuQRL/DvqLP45cZ1N4GtS+J3jrVk976+pkdQO/0e8sOoEcIO5BEX8Ju+0rbb9t+1/Y9/eihFdsjtrfZ3mK72edeVtrea3v7uGUn2t5g+53idsI59vrU20O2dxbrbovtq/rU2ym2/2D7Tdtv2L6zWN7XdVfSV0/WW88/s9ueJul/Jf2zpA8kvSppcUS82dNGWrA9IqkREX3/AobtiyV9IunXEfEPxbJ/lbQvIh4t/lDOioh/GZDeHpL0Sb+n8S5mK5o7fppxSddI+pH6uO5K+rpePVhv/diyny/p3Yh4LyK+lLRa0tV96GPgRcRGSfu+sfhqSauK+6s09p+l51r0NhAiYldEvFbc3y/p8DTjfV13JX31RD/CfrKk98f9/oEGa773kPR725ttL+l3MxOYExG7ivu7Jc3pZzMTaDuNdy99Y5rxgVl3nUx/XhU76L5tQUScJ2mRpKXF29WBFGOfwQbp2OmkpvHulQmmGf+Lfq67Tqc/r6ofYd8p6ZRxv88rlg2EiNhZ3O6V9KwGbyrqPYdn0C1u9/a5n78YpGm8J5pmXAOw7vo5/Xk/wv6qpNNsz7c9XdIPJa3tQx/fYvv4YseJbB8v6fsavKmo10q6ubh/s6Q1fezlawZlGu9W04yrz+uu79OfR0TPfyRdpbE98v8n6d5+9NCir7+X9Ofi541+9ybpaY29rftKY/s2bpX0t5JelPSOpP+RdOIA9fafkrZJ2qqxYM3tU28LNPYWfaukLcXPVf1edyV99WS98XVZIAl20AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEv8PzXkyT/Yg+H4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "image_index = 2653\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "predict = x_test[image_index].reshape(28,28)\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
